
"""
this script converts the wig file (ribosome profiling) into training datasets
"""
import numpy as np
import os
import json
import argparse
from itertools import groupby
from Bio import SeqIO
from BCBio import GFF
np.seterr(invalid='raise')

# load fasta files
def fasta_iter(fasta_name):
    """
    given a fasta file, yield tuples of header, sequence
    """
    with open(fasta_name) as fasta_file:
        # ditch the boolean (x[0]) and just keep the header or sequence since
        # we know they alternate.
        faiter = (x[1] for x in groupby(fasta_file, lambda line: line[0] == ">"))
        for header in faiter:
            header = header.__next__()[1:].strip() # drop the ">"
            seq = "".join(s.strip() for s in faiter.__next__()) # join all sequences
            print("Sequence loaded.", header)
            yield header, seq


# read wig files
def read_wig(filename):
    '''
    read wig file from filename
    read forward and reverse direction seperately
    Ribo: total number of ribosomes for data normalization (Amin & Zhang et al.,2021)
    '''
    
    # read forward direction
    wig1 = {}
    chrom_all = []
    # /home/zzz0054/chen_data/Riboformer/datasets/AA/AuxinA0FootprintR4_DNA_f.wig
    # /home/zzz0054/chen_data/Riboformer/datasets/AA/AuxinA0FootprintR4_f.wig
    with open(filename + '_f.wig', 'r') as read_file:
        lines = read_file.readlines()
        for j in range(1, len(lines)):
            if lines[j][0] == 'f':
                chrom_all.append(lines[j].split(' ')[1].split('=')[1].replace('chr', ''))
                if j > 2:
                    wig1[chrom_all[-2]] = np.array(read)
                read = []
            else:
                read.append(float(lines[j]))
    wig1[chrom_all[-1]] = np.array(read)
    
    wig2 = {}
    chrom_all = []
    with open(filename + '_r.wig', 'r') as read_file:
        lines = read_file.readlines()
        for j in range(1, len(lines)):
            if lines[j][0] == 'f':
                chrom_all.append(lines[j].split(' ')[1].split('=')[1].replace('chr', ''))
                if j > 2:
                    wig2[chrom_all[-2]] = np.array(read)
                read = []
            else:
                read.append(float(lines[j]))
    wig2[chrom_all[-1]] = np.array(read)
        
    wig_total = {}
    for c in wig1.keys():
        wig_total[c] = np.vstack([np.zeros(wig1[c].shape), \
                             wig1[c], \
                             wig2[c]] ).transpose()
    return wig_total


#get the codon density
def sum_adjac(RD):
    return RD[:3 * (len(RD)//3)].reshape(-1,3).sum(1) 


# Generate training dataset
def generate_training(my_data2, seq, Dwig1, Dwig2, wsize, Ctable, P_site = 14, thres = 25):
    '''
    input
    my_data2: gff file of the genome, stores the positions of open reading frames
    seq: DNA sequence of the genome
    Dwig1: sequencing reads from condition 1, generated by read_wig function
    Dwig2: sequencing reads from condition 2, generated by read_wig function
    P_site: 14 for the Mohammad et al., eLife paper
    wsize: length of the context, default 40
    thres: use the top % of highly expressed genes

    output:
    x_c: feature variable, 0:40 is sequencing reads in the 40 bp window in condition1,
        -40:0 is codon number in the window
    y_c: sequencing read in the target position in condition 2
    z_c: target position in the genome

    comments:
    x_y and y_c are log transformed
    '''
    x_c = []
    y_c = []
    z_c = []
    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'}
    
    RD_mean_list = []
    for i, data in enumerate(my_data2):
        
        # number of nt to add in the beginning and end
        n = 30
        gene_len = 200
        
        # 3' is aligned
        if data[2] == 1:
            # positive strand
            # This code appears to be working with RNA/genomic data processing:

            # Breaking down the components:

            # Dwig1 seems to be a 2D array/matrix containing sequence data
            # data[0] and data[1] are likely start and end positions
            # P_site appears to be an offset value for the P-site position
            # n is probably a window size parameter
            # The , 1 at the end indicates selecting column 1 from the 2D array
            # The operation:

            # Takes a slice of Dwig1 array
            # Start position: (int(data[0]) - 1 - n) + P_site
            # End position: int(data[1]) + n + P_site
            # Selects only column 1 from this slice
            # Purpose:

            # This code likely extracts a region of interest around a ribosome P-site
            # The -1 adjusts for 0-based indexing
            # The ±n extends the window around the region
            # P_site adjusts for the P-site offset
            if data[1] - data[0] > gene_len:
                RD1 = Dwig1[(int(data[0]) - 1 - n) + P_site : int(data[1]) + n + P_site, 1]
        else:
            # negtive strand
            if data[1] - data[0] > gene_len:
                RD1 = Dwig1[(int(data[0]) - 1 - n) - P_site : int(data[1]) + n - P_site, 2]
                RD1 = RD1[::-1]
        if data[1] - data[0] > gene_len:
            RD_mean_list.append(np.mean(RD1))
            
    RD_thres1 = np.percentile(RD_mean_list, 100 - thres)
    normal = 0.005/np.mean(RD_mean_list)

    for i, data in enumerate(my_data2):
        
        # number of nt to add in the beginning and end
        n = 30
        gene_len = 200
        
        # 3' is aligned
        
        # This loop processes RNA sequence/ribosome profiling data using a sliding window approach:

        # Window Operation:

        # wsize is window size
        # Loop runs from wsize/2 to len(RD1) - wsize/2
        # Creates sliding window centered at position m
        # Data Collection:

        # x_c: Training features combining:
        # Log-transformed read counts from window
        # Position information
        # Codon vectors
        # y_c: Target values (log-transformed read counts from RD2)
        # z_c: Position tracking
        # Meaning of z_c
        # z_c stores position information as pairs:

        # i: Likely an index of the current sequence/gene
        # m: Current position in the window
        # This appears to be building a dataset for machine learning, where:

        # z_c helps track where predictions come from in the original sequence
        # Used for mapping predictions back to source positions later
        
        if data[2] == 1:
            # positive strand
            if data[1] - data[0] > gene_len:
                RD1 = Dwig1[(int(data[0]) - 1 - n) + P_site : int(data[1]) + n + P_site, 1]
                RD2 = Dwig2[(int(data[0]) - 1 - n) + P_site : int(data[1]) + n + P_site, 1]
                seq_t = seq[int(data[0]) - 1 - n : int(data[1]) + n]
        else:
            # negtive strand
            if data[1] - data[0] > gene_len:
                RD1 = Dwig1[(int(data[0]) - 1 - n) - P_site : int(data[1]) + n - P_site, 2]
                RD1 = RD1[::-1]
                RD2 = Dwig2[(int(data[0]) - 1 - n) - P_site : int(data[1]) + n - P_site, 2]
                RD2 = RD2[::-1]
                seq_t = seq[int(data[0]) - 1 - n : int(data[1]) + n]
                seq_t = ''.join(complement.get(base, base) for base in reversed(seq_t))
        
        
        if data[1] - data[0] > gene_len and np.mean(RD1) > RD_thres1:
            codons = list(seq_t[n : n + 3] for n in range(0, len(seq_t), 3))
            codons_v = np.zeros((len(codons),))
            for m, codon in enumerate(codons):
                if codon in Ctable:
                    codons_v[m] = Ctable.index(codon)

            RD1 = sum_adjac(RD1)
            RD2 = sum_adjac(RD2)
            
            rc1 = 10000*normal
            #  norm = 0.005/np.mean(RD1_mean_list)
            rc2 = 32
            rc3 = 100

            for m in range(int(wsize/2), len(RD1) - int(wsize/2)):
                # training variables
                x_c.append(
                    np.concatenate([np.log2(RD1[m - int(wsize/2) : m + int(wsize/2)] * rc1 + rc2) * rc3,
                                    np.array([m, np.log2(np.mean(RD1[int(wsize/2) : m + int(wsize/2)]) * rc1 + rc2) * rc3]),
                                    codons_v[m - int(wsize/2) : m + int(wsize/2)]])
                )
                
                # prediction variables
                y_c.append(np.log2(RD2[m] * rc1 + rc2) * rc3)
                
                # positions of the calculating codons
                z_c.append([i, m])

    return x_c, y_c, z_c

# 这里是不是只是其中一种

def main():
    
    parser = argparse.ArgumentParser(
        description = __doc__,
        formatter_class = argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument('-w', '--wsize', default = 40, type = int, 
                        help = 'window size (AA) for model training')
    parser.add_argument('-th', '--threshold', default = 25, type = int, 
                        help = 'expression threshold (percentile) for model training')
    parser.add_argument('-d', '--data_dir', default = '/home/zzz0054/chen_data/Riboformer/datasets/AA/', type = str,
                        help = 'data folder name')
    parser.add_argument('-r', '--reference', default = 'AuxinC0FootprintR4_DNA', type = str,
                        help = 'reference dataset name')
    parser.add_argument('-p', '--psite', default = 14, type = int,
                        help = 'offset for p site position')
    parser.add_argument('-t', '--target', default = 'AuxinA0FootprintR4_DNA', type = str,
                        help = 'target dataset name')
                
    args = parser.parse_args()

    filepath = {'exp1': args.reference,
                'exp2': args.target,
                'x_input': 'xc.txt',
                'y_output': 'yc.txt',
                'z_index': 'zc.txt',
                'y_pred': 'ypred.txt',
                }
    # parpath = os.path.dirname(os.getcwd())
    # datapath = parpath + '/Riboformer/datasets/' + args.data_dir + '/'
    for key in filepath.keys():
        filepath[key] = args.data_dir + filepath[key]
    
    all_files = os.listdir(args.data_dir)
    fasta_file = [f for f in all_files if f.endswith('.fasta')]
    gff_file = [f for f in all_files if f.endswith('.gff3')]

    # load codon table
    with open('/home/zzz0054/chen_data/Riboformer/Riboformer/codon_table.json') as f:
        Ctable = json.load(f)
        
    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'}

    # load ribosome footprints
    print("---------------------------------------------")
    print("Loading ribosome densities.")
    Dwig1 = read_wig(filepath['exp1'])
    Dwig2 = read_wig(filepath['exp2'])
    print("Finish reading the ribosome footprints.")

    # load genome sequences
    print("---------------------------------------------")
    print("Loading genome sequences.")
    seq_dict = {}
    for record in SeqIO.parse(args.data_dir + fasta_file[0], "fasta"):
        seq_dict[record.id] = record.seq
        print(record.id + " len is " + str(len(record.seq)))

    # generate training datasets
    print("---------------------------------------------")
    x_c_total = []
    y_c_total = []
    z_c_total = []
    z_gene = 0
    for key in seq_dict.keys():
        if key != 'Mito':
            limit_info = dict(gff_id=[key], gff_type=["CDS"])
            in_handle = open(args.data_dir + gff_file[0])
            gff_data = []
            for rec in GFF.parse(in_handle, limit_info=limit_info):
                for j in range(len(rec.features)):
                    # position need to plus 1 before passing to the generate training set function
                    # seq[start.position: end.position] is the right index for the DNA sequence
                    gff_data.append([rec.features[j].location.start.position + 1,
                                     rec.features[j].location.end.position,
                                     rec.features[j].location.strand])
            in_handle.close()
            gff_data = np.array(gff_data)

            x_c, y_c, z_c = generate_training(gff_data, seq_dict[key], Dwig1[key], Dwig2[key], args.wsize, Ctable, int(args.psite), float(args.threshold))
            x_c_total = x_c_total + x_c
            y_c_total = y_c_total + y_c
            z_c_total = z_c_total + z_c
            z_gene += len(np.unique(np.array(z_c)[:, 0]))

    x_c_total = np.array(x_c_total)
    y_c_total = np.array(y_c_total)
    z_c_total = np.array(z_c_total)
    print(f"Finish generating the training datasets. Number of unique genes is {z_gene}")

    np.savetxt(filepath['x_input'], x_c_total, delimiter="\t")
    np.savetxt(filepath['y_output'], y_c_total, delimiter="\t")
    np.savetxt(filepath['z_index'], z_c_total, delimiter="\t")
    
    print(f"Datasets saved. Number of samples is {len(x_c)}.")

    

if __name__ == '__main__':
    main()
    
# x_c [82] -> y_c (y)

# 12345->6789
# 123456->7
# 1234567->8
# 12345678->9
# 12345 6789
